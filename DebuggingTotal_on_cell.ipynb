{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/patel/adithya/scenv/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, average_precision_score, recall_score,\n",
    "    precision_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from flaml import AutoML\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_dir_path = \"/n/groups/patel/adithya/Syn18_Log_Dir_Total_on_cell/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata is loaded\n",
      "Number of cases in training: 21958\n",
      "Number of cases in test: 131\n"
     ]
    }
   ],
   "source": [
    "exp_type = 'maximal'\n",
    "cell_type = 'Mic'\n",
    "\n",
    "# Load the data\n",
    "metadata = pd.read_parquet('/home/adm808/New_CellMetadataSyn1848517.parquet')\n",
    "print(\"Metadata is loaded\")\n",
    "\n",
    "# Process APOE genotype as categorical -- Hot encoding of apoe_genotype\n",
    "metadata = pd.get_dummies(metadata, columns=[\"apoe_genotype\"])\n",
    "apoe_genotype_columns = [col for col in metadata.columns if col.startswith(\"apoe_genotype_\")]\n",
    "\n",
    "\n",
    "# Stratified Shuffle Split based on `sample_id`to split metadata\n",
    "# Define Alzheimer's or control status directly based on `age_first_ad_dx`\n",
    "metadata = metadata.copy()\n",
    "metadata['alzheimers_or_control'] = metadata['age_first_ad_dx'].notnull().astype(int)\n",
    "\n",
    "# Extract unique sample IDs and their associated Alzheimer's/control status -- drop duplicates\n",
    "sample_summary = metadata[['sample', 'alzheimers_or_control', 'msex']].drop_duplicates()\n",
    "\n",
    "# I need to create a combined stratification variable\n",
    "sample_summary['stratify_group'] = sample_summary['alzheimers_or_control'].astype(str) + \"_\" + sample_summary['msex'].astype(str)\n",
    "\n",
    "# Perform stratified train-test split on `sample_id`, stratified by `alzheimers_or_control`\n",
    "train_samples, test_samples = train_test_split(\n",
    "    sample_summary['sample'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=sample_summary['stratify_group']\n",
    ")\n",
    "\n",
    "# Filter metadata by train and test `sample_id`\n",
    "train_metadata = metadata[metadata['sample'].isin(train_samples)]\n",
    "test_metadata = metadata[metadata['sample'].isin(test_samples)]\n",
    "\n",
    "\n",
    "# We only want to predict on one cell type but train the model on all cell types so we filter test_metadata\n",
    "test_metadata = test_metadata[test_metadata['broad.cell.type'] == cell_type]\n",
    "\n",
    "\n",
    "print(f\"Number of cases in training: {sum(train_metadata['alzheimers_or_control'])}\")\n",
    "print(f\"Number of cases in test: {sum(test_metadata['alzheimers_or_control'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases in test: 131\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of cases in test: {sum(test_metadata['alzheimers_or_control'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55677\n",
      "569\n"
     ]
    }
   ],
   "source": [
    "print(len(train_metadata))\n",
    "print(len(test_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>alzheimers_or_control</th>\n",
       "      <th>msex</th>\n",
       "      <th>stratify_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample  alzheimers_or_control  msex stratify_group\n",
       "0          1                      0   1.0          0_1.0\n",
       "312        2                      0   1.0          0_1.0\n",
       "432        3                      0   1.0          0_1.0\n",
       "847        4                      1   1.0          1_1.0\n",
       "1694       5                      0   0.0          0_0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases in training: 529\n",
      "                       TAG    projid     tsne1      tsne2  pre.cluster  \\\n",
      "62407   AACTTTCAGGATGGTC.1  11409232  4.511704 -48.516566           13   \n",
      "62408   ACGGGCTCAATCAGAA.1  11409232  5.457969 -52.755649           13   \n",
      "62409   ACTTACTGTGAAATCA.1  11409232  7.256031  58.172625           13   \n",
      "62410   AGCGGTCAGATGTTAG.1  11409232  6.462830 -52.549235           13   \n",
      "62411   AGTGAGGGTGGTAACG.1  11409232  4.764862 -48.622495           13   \n",
      "...                    ...       ...       ...        ...          ...   \n",
      "64322  CCGTTCACAGCGAACA.48  11302830  5.086001 -53.544812           13   \n",
      "64323  CCTTCGATCAAACCGT.48  11302830  4.228903 -52.145368           13   \n",
      "64324  CGATGTAAGGGTTTCT.48  11302830  7.317785 -39.182029           13   \n",
      "64325  TAAGAGATCGTGGGAA.48  11302830  2.416547  54.937268           13   \n",
      "64326  TGGCTGGAGTGAATTG.48  11302830  2.664527 -52.428202           13   \n",
      "\n",
      "      broad.cell.type Subcluster  msex     age_first_ad_dx  braaksc  ...  \\\n",
      "62407             Mic       Mic1   1.0                None      3.0  ...   \n",
      "62408             Mic       Mic1   1.0                None      3.0  ...   \n",
      "62409             Mic       Mic2   1.0                None      3.0  ...   \n",
      "62410             Mic       Mic1   1.0                None      3.0  ...   \n",
      "62411             Mic       Mic1   1.0                None      3.0  ...   \n",
      "...               ...        ...   ...                 ...      ...  ...   \n",
      "64322             Mic       Mic1   1.0  84.522929500342229      3.0  ...   \n",
      "64323             Mic       Mic1   1.0  84.522929500342229      3.0  ...   \n",
      "64324             Mic       Mic3   1.0  84.522929500342229      3.0  ...   \n",
      "64325             Mic       Mic0   1.0  84.522929500342229      3.0  ...   \n",
      "64326             Mic       Mic0   1.0  84.522929500342229      3.0  ...   \n",
      "\n",
      "      ceradsc  cogdx  dcfdx_lv  individualID sample apoe_genotype_23.0  \\\n",
      "62407     4.0    2.0       2.0      R8744945      1              False   \n",
      "62408     4.0    2.0       2.0      R8744945      1              False   \n",
      "62409     4.0    2.0       2.0      R8744945      1              False   \n",
      "62410     4.0    2.0       2.0      R8744945      1              False   \n",
      "62411     4.0    2.0       2.0      R8744945      1              False   \n",
      "...       ...    ...       ...           ...    ...                ...   \n",
      "64322     2.0    4.0       4.0      R3900996     48              False   \n",
      "64323     2.0    4.0       4.0      R3900996     48              False   \n",
      "64324     2.0    4.0       4.0      R3900996     48              False   \n",
      "64325     2.0    4.0       4.0      R3900996     48              False   \n",
      "64326     2.0    4.0       4.0      R3900996     48              False   \n",
      "\n",
      "       apoe_genotype_33.0  apoe_genotype_34.0  apoe_genotype_44.0  \\\n",
      "62407                True               False               False   \n",
      "62408                True               False               False   \n",
      "62409                True               False               False   \n",
      "62410                True               False               False   \n",
      "62411                True               False               False   \n",
      "...                   ...                 ...                 ...   \n",
      "64322               False                True               False   \n",
      "64323               False                True               False   \n",
      "64324               False                True               False   \n",
      "64325               False                True               False   \n",
      "64326               False                True               False   \n",
      "\n",
      "       alzheimers_or_control  \n",
      "62407                      0  \n",
      "62408                      0  \n",
      "62409                      0  \n",
      "62410                      0  \n",
      "62411                      0  \n",
      "...                      ...  \n",
      "64322                      1  \n",
      "64323                      1  \n",
      "64324                      1  \n",
      "64325                      1  \n",
      "64326                      1  \n",
      "\n",
      "[1351 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "train_metadata_check = train_metadata[train_metadata['broad.cell.type'] == cell_type]\n",
    "print(f\"Number of cases in training: {sum(train_metadata_check['alzheimers_or_control'])}\")\n",
    "print(train_metadata_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6665     10\n",
      "312       2\n",
      "23908    32\n",
      "23006    30\n",
      "16553    22\n",
      "18385    25\n",
      "15890    21\n",
      "21667    28\n",
      "20506    27\n",
      "26370    36\n",
      "0         1\n",
      "15464    20\n",
      "4242      8\n",
      "13149    17\n",
      "23269    31\n",
      "13781    18\n",
      "34757    48\n",
      "29160    41\n",
      "6066      9\n",
      "14739    19\n",
      "30285    42\n",
      "10319    14\n",
      "22176    29\n",
      "26958    37\n",
      "33230    46\n",
      "28129    39\n",
      "19284    26\n",
      "847       4\n",
      "12668    16\n",
      "17355    23\n",
      "27488    38\n",
      "30903    43\n",
      "3629      7\n",
      "31956    44\n",
      "26267    35\n",
      "8478     11\n",
      "28537    40\n",
      "1694      5\n",
      "Name: sample, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train samples: {train_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test samples: 432       3\n",
      "17757    24\n",
      "34185    47\n",
      "25663    34\n",
      "25077    33\n",
      "2962      6\n",
      "11132    15\n",
      "32504    45\n",
      "9310     13\n",
      "8770     12\n",
      "Name: sample, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTest samples: {test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  6 12 13 15 24 33 34 45 47]\n"
     ]
    }
   ],
   "source": [
    "print(test_metadata['sample'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_type = pd.concat([train_metadata_check, test_metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample\n",
       "15    111\n",
       "5     105\n",
       "3     102\n",
       "28     86\n",
       "24     84\n",
       "44     73\n",
       "7      73\n",
       "10     72\n",
       "11     69\n",
       "6      65\n",
       "26     62\n",
       "16     60\n",
       "45     55\n",
       "47     48\n",
       "25     47\n",
       "4      47\n",
       "38     46\n",
       "21     45\n",
       "17     44\n",
       "34     44\n",
       "19     43\n",
       "29     39\n",
       "22     34\n",
       "2      33\n",
       "13     32\n",
       "32     31\n",
       "14     31\n",
       "18     28\n",
       "36     26\n",
       "40     25\n",
       "41     25\n",
       "20     25\n",
       "39     25\n",
       "46     25\n",
       "1      21\n",
       "30     20\n",
       "42     18\n",
       "33     18\n",
       "23     14\n",
       "43     13\n",
       "31     12\n",
       "9      11\n",
       "12     10\n",
       "48      6\n",
       "37      5\n",
       "27      5\n",
       "8       4\n",
       "35      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cell_type['sample'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene matrix is loaded\n",
      "                    FO538757.2  SAMD11     NOC2L  KLHL17  PLEKHN1\n",
      "AAACGGGAGATCCCGC.1    0.000000     0.0  0.000000     0.0      0.0\n",
      "AAATGCCTCCAATGGT.1    6.919779     0.0  0.000000     0.0      0.0\n",
      "AACCATGTCAGTGCAT.1   11.637401     0.0  0.000000     0.0      0.0\n",
      "AACCATGTCTGTACGA.1    0.000000     0.0  6.974242     0.0      0.0\n",
      "AACCGCGTCCGCATAA.1    7.831354     0.0  0.000000     0.0      0.0\n",
      "Printing dimensionality of X_train and X_test initallly\n",
      "(55677, 17926)\n",
      "(569, 17926)\n",
      "Printing dimensionality of X_train and X_test post filtering and merging\n",
      "(55677, 2440)\n",
      "(569, 2440)\n"
     ]
    }
   ],
   "source": [
    "# Function to select and drop missing genes\n",
    "def select_missing_genes(filtered_matrix):\n",
    "    mean_threshold = 1\n",
    "    missingness_threshold = 95\n",
    "\n",
    "    mean_gene_expression = filtered_matrix.mean(axis=0)\n",
    "    missingness = (filtered_matrix == 0).sum(axis=0) / filtered_matrix.shape[0] * 100\n",
    "    null_expression = (missingness > missingness_threshold) & (mean_gene_expression < mean_threshold)\n",
    "    genes_to_drop = filtered_matrix.columns[null_expression].tolist()\n",
    "\n",
    "    return genes_to_drop\n",
    "\n",
    "# Load and transpose gene expression matrices\n",
    "gene_matrix = pd.read_parquet('/home/adm808/NormalizedCellMatrixSyn18485175.parquet').T\n",
    "print(\"Gene matrix is loaded\")\n",
    "print(gene_matrix.iloc[:, :5].head())\n",
    "\n",
    "# Defining training and testing matrices\n",
    "train_matrix = gene_matrix.loc[train_metadata['TAG']]\n",
    "test_matrix = gene_matrix.loc[test_metadata['TAG']]\n",
    "\n",
    "print(\"Printing dimensionality of X_train and X_test initallly\")\n",
    "print(train_matrix.shape)\n",
    "print(test_matrix.shape)\n",
    "\n",
    "# Filter missing genes\n",
    "train_matrix_filtered = train_matrix.drop(select_missing_genes(train_matrix), axis=1)\n",
    "test_matrix_filtered = test_matrix.drop(select_missing_genes(test_matrix), axis=1)\n",
    "\n",
    "# Merge the train and test matrices with their respective metadata files\n",
    "\n",
    "train_data = train_matrix_filtered.merge(\n",
    "    train_metadata[['TAG', 'msex', 'sample', 'broad.cell.type', 'alzheimers_or_control', 'age_death', 'educ', 'cts_mmse30_lv', 'pmi'] + apoe_genotype_columns],\n",
    "    left_index=True,\n",
    "    right_on='TAG',\n",
    "    how='inner'\n",
    ").set_index('TAG')\n",
    "\n",
    "test_data = test_matrix_filtered.merge(\n",
    "    test_metadata[['TAG', 'msex', 'sample', 'broad.cell.type', 'alzheimers_or_control', 'age_death', 'educ', 'cts_mmse30_lv', 'pmi'] + apoe_genotype_columns],\n",
    "    left_index=True,\n",
    "    right_on='TAG',\n",
    "    how='inner'\n",
    ").set_index('TAG')\n",
    "\n",
    "\n",
    "# Clean column names for model compatibility\n",
    "train_data.columns = train_data.columns.str.replace(r'[^A-Za-z0-9_]+', '', regex=True)\n",
    "test_data.columns = test_data.columns.str.replace(r'[^A-Za-z0-9_]+', '', regex=True)\n",
    "\n",
    "# Ensure common genes are used between training and testing sets\n",
    "common_genes = train_data.columns.intersection(test_data.columns)\n",
    "X_train = train_data[common_genes]\n",
    "X_test = test_data[common_genes]\n",
    "\n",
    "# Drop the alzheimers or control column from the dataset\n",
    "X_train = X_train.drop(columns=['alzheimers_or_control'])\n",
    "X_test = X_test.drop(columns=['alzheimers_or_control'])\n",
    "\n",
    "# Map original column names to cleaned names for later interpretability\n",
    "original_columns = common_genes  # Use common genes after filtering\n",
    "cleaned_columns = original_columns.str.replace(r'[^A-Za-z0-9_]+', '', regex=True)\n",
    "column_mapping = dict(zip(cleaned_columns, original_columns))\n",
    "\n",
    "# Define the target variable\n",
    "y_train = train_data['alzheimers_or_control']\n",
    "y_test = test_data['alzheimers_or_control']\n",
    "\n",
    "print(\"Printing dimensionality of X_train and X_test post filtering and merging\")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Trying a new method of creating cross validation folds:\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "\n",
    "def generate_valid_folds(X, y, groups, n_splits=10, max_retries=100):\n",
    "    \"\"\"\n",
    "    Generate valid folds for StratifiedGroupKFold to ensure no fold has only one class.\n",
    "    Retries until valid folds are created.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        retries += 1\n",
    "        valid_folds = True\n",
    "        stratified_group_kfold = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=np.random.randint(1000))\n",
    "        \n",
    "        # Generate folds\n",
    "        folds = list(stratified_group_kfold.split(X, y, groups))\n",
    "\n",
    "        # Check for class balance in validation folds\n",
    "        for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "            train_y, val_y = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            if len(val_y.unique()) < 2:  # Check if validation set has both classes\n",
    "                print(f\"Retry {retries}: Fold {fold + 1} has only one class. Retrying...\")\n",
    "                valid_folds = False\n",
    "                break\n",
    "\n",
    "        if valid_folds:\n",
    "            print(f\"Valid folds generated after {retries} retries.\")\n",
    "            return folds  # Return valid folds\n",
    "\n",
    "    raise ValueError(\"Unable to generate valid folds after maximum retries.\")\n",
    "\n",
    "\n",
    "# This seciton is throwing an error, seems like flaml has no argument to create custom folds, must follow approach taken below:\n",
    "# # Generate valid folds\n",
    "# valid_folds = generate_valid_folds(\n",
    "    # X_train,  # Feature matrix\n",
    "#     y_train,  # Target variable\n",
    "#     groups=train_metadata['sample'],  # Group variable\n",
    "#     n_splits=10,\n",
    "#     max_retries=100\n",
    "# )\n",
    "\n",
    "#cell_log_dir = os.path.join(log_dir_path, cell_type)\n",
    "\n",
    "# Create the directory if it doesn’t exist\n",
    "#os.makedirs(cell_log_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# For task one I am training on all cell types, but testing only on one specific cell type. Therefore, I will subset just the testing sets for cell type:\n",
    "\n",
    "# Dropping samples from the dataset\n",
    "X_train = X_train.drop(columns=['sample'])\n",
    "X_test = X_test.drop(columns=['sample'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55677, 2439), (569, 2439))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
