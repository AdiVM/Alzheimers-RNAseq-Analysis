{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13538e56-c60a-4d2b-a4c2-83c7975c051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metadata is loaded\n",
      "Test metadata is loaded\n",
      "Number of cases in training: 26148\n",
      "Number of cases in test: 63354\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_metadata = pd.read_parquet('/home/adm808/CellMetadataSyn18485175.parquet')\n",
    "print(\"Train metadata is loaded\")\n",
    "test_metadata = pd.read_csv('/home/adm808/UpdatedCellMetadataSyn16780177.csv', low_memory=False)\n",
    "print(\"Test metadata is loaded\")\n",
    "\n",
    "# Process APOE genotype as categorical\n",
    "combined_metadata = pd.concat([train_metadata, test_metadata], keys=['train', 'test'])\n",
    "combined_metadata = pd.get_dummies(combined_metadata, columns=[\"apoe_genotype\"])\n",
    "\n",
    "# Split back into train and test metadata\n",
    "train_metadata = combined_metadata.xs('train')\n",
    "test_metadata = combined_metadata.xs('test')\n",
    "\n",
    "# Define Alzheimer's or control status\n",
    "train_metadata = train_metadata.copy()\n",
    "test_metadata = test_metadata.copy()\n",
    "train_metadata['alzheimers_or_control'] = train_metadata['age_first_ad_dx'].notnull().astype(int)\n",
    "test_metadata['alzheimers_or_control'] = test_metadata['age_first_ad_dx'].notnull().astype(int)\n",
    "\n",
    "print(f\"Number of cases in training: {sum(train_metadata['alzheimers_or_control'])}\")\n",
    "print(f\"Number of cases in test: {sum(test_metadata['alzheimers_or_control'])}\")\n",
    "\n",
    "# Function to select and drop missing genes\n",
    "def select_missing_genes(filtered_matrix):\n",
    "    mean_threshold = 1\n",
    "    missingness_threshold = 95\n",
    "\n",
    "    mean_gene_expression = filtered_matrix.mean(axis=0)\n",
    "    missingness = (filtered_matrix == 0).sum(axis=0) / filtered_matrix.shape[0] * 100\n",
    "    null_expression = (missingness > missingness_threshold) & (mean_gene_expression < mean_threshold)\n",
    "    genes_to_drop = filtered_matrix.columns[null_expression].tolist()\n",
    "\n",
    "    return genes_to_drop\n",
    "\n",
    "# Transpose and load gene expression matrices\n",
    "# Load and transpose gene expression matrices\n",
    "train_matrix = pd.read_parquet('/home/adm808/NormalizedCellMatrixSyn18485175.parquet').T\n",
    "test_matrix = pd.read_parquet('/home/adm808/NormalizedCellMatrixSyn16780177.parquet').T\n",
    "print(\"Train and test matrices are loaded\")\n",
    "print(train_matrix.iloc[:, :5].head())\n",
    "print(test_matrix.iloc[:, :5].head())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Filter missing genes\n",
    "train_matrix_filtered = train_matrix.drop(select_missing_genes(train_matrix), axis=1)\n",
    "test_matrix_filtered = test_matrix.drop(select_missing_genes(test_matrix), axis=1)\n",
    "\n",
    "# Merge train and test matrices with metadata\n",
    "train_data = train_matrix_filtered.merge(train_metadata.loc[: ['TAG', 'msex', 'broad.cell.type', 'apoe.genotype']], left_index=True, right_on='TAG', how='inner').set_index('TAG')\n",
    "test_data = test_matrix_filtered.merge(test_metadata.loc[: ['TAG', 'msex', 'broad.cell.type', 'apoe.genotype']], left_index=True, right_on='TAG', how='inner').set_index('TAG')\n",
    "\n",
    "\n",
    "# Clean column names for model compatibility\n",
    "train_data.columns = train_data.columns.str.replace(r'[^A-Za-z0-9_]+', '', regex=True)\n",
    "test_data.columns = test_data.columns.str.replace(r'[^A-Za-z0-9_]+', '', regex=True)\n",
    "\n",
    "# Ensure common genes are used between training and testing sets\n",
    "common_genes = train_data.columns.intersection(test_data.columns)\n",
    "X_train = train_data[common_genes]\n",
    "X_test = test_data[common_genes]\n",
    "\n",
    "# Map original column names to cleaned names for later interpretability\n",
    "original_columns = common_genes  # Use common genes after filtering\n",
    "cleaned_columns = original_columns.str.replace(r'[^A-Za-z0-9_]+', '', regex=True)\n",
    "column_mapping = dict(zip(cleaned_columns, original_columns))\n",
    "\n",
    "# Define the target variable\n",
    "y_train = train_data['alzheimers_or_control']\n",
    "y_test = test_data['alzheimers_or_control']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "# Run maximal classification experiment on all data\n",
    "output_csv = f'{log_dir_path}maximal_output_log.csv'\n",
    "print(\"Starting all features classification\")\n",
    "maximal_classifier = AutoML()\n",
    "maximal_classifier.fit(\n",
    "    X_train, y_train,\n",
    "    task=\"classification\", time_budget=1000, metric='log_loss',\n",
    "    n_jobs=-1, eval_method='cv', n_splits=10, split_type='stratified',\n",
    "    log_training_metric=True, early_stop=True, seed=239875, estimator_list=['lgbm']\n",
    ")\n",
    "\n",
    "# Predictions and optimal threshold using Youden's J statistic\n",
    "y_prob_train = maximal_classifier.predict_proba(X_train)[:, 1]\n",
    "y_prob_test = maximal_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "youden_stats = [(recall_score(y_train, (y_prob_train >= t).astype(int)) +\n",
    "                 recall_score(y_train, (y_prob_train >= t).astype(int), pos_label=0) - 1)\n",
    "                for t in thresholds]\n",
    "optimal_threshold = thresholds[np.argmax(youden_stats)]\n",
    "\n",
    "y_pred_train_optimal = (y_prob_train >= optimal_threshold).astype(int)\n",
    "y_pred_test_optimal = (y_prob_test >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    'train_accuracy': accuracy_score(y_train, y_pred_train_optimal),\n",
    "    'train_roc_auc': roc_auc_score(y_train, y_prob_train),\n",
    "    'train_avg_precision': average_precision_score(y_train, y_prob_train),\n",
    "    'train_recall': recall_score(y_train, y_pred_train_optimal),\n",
    "    'train_precision': precision_score(y_train, y_pred_train_optimal),\n",
    "    'train_f1': f1_score(y_train, y_pred_train_optimal),\n",
    "    'train_mcc': matthews_corrcoef(y_train, y_pred_train_optimal),\n",
    "    'test_accuracy': accuracy_score(y_test, y_pred_test_optimal),\n",
    "    'test_roc_auc': roc_auc_score(y_test, y_prob_test),\n",
    "    'test_avg_precision': average_precision_score(y_test, y_prob_test),\n",
    "    'test_recall': recall_score(y_test, y_pred_test_optimal),\n",
    "    'test_precision': precision_score(y_test, y_pred_test_optimal),\n",
    "    'test_f1': f1_score(y_test, y_pred_test_optimal),\n",
    "    'test_mcc': matthews_corrcoef(y_test, y_pred_test_optimal)\n",
    "}\n",
    "\n",
    "pd.DataFrame([metrics]).to_csv(output_csv, index=False)\n",
    "\n",
    "# Feature importance for top 100 features and I try to avoid the mismatch error that was occuring\n",
    "# if maximal_classifier.feature_importances_ is not None:\n",
    "#     # Retrieve the features actually used by the model\n",
    "#     used_features = maximal_classifier.feature_names_in_\n",
    "\n",
    "#     # Create the feature importance Series with used features only\n",
    "#     feature_importance = pd.Series(maximal_classifier.feature_importances_, index=used_features)\n",
    "\n",
    "#     # Get the top 100 features and map them back to original names for interpretability\n",
    "#     top_features_cleaned = feature_importance.nlargest(100).index\n",
    "#     top_features_original = [column_mapping.get(feature, feature) for feature in top_features_cleaned]\n",
    "    \n",
    "#     # Refit model on top features\n",
    "#     X_train_top = X_train[top_features_cleaned]\n",
    "#     X_test_top = X_test[top_features_cleaned]\n",
    "\n",
    "#     top_maximal_classifier = AutoML()\n",
    "#     top_maximal_classifier.fit(\n",
    "#         X_train_top, y_train,\n",
    "#         task=\"classification\", time_budget=800, metric='log_loss',\n",
    "#         n_jobs=-1, eval_method='cv', n_splits=10, split_type='stratified',\n",
    "#         log_training_metric=True, early_stop=True, seed=239875, estimator_list=['lgbm']\n",
    "#     )\n",
    "\n",
    "#     y_prob_train_top = top_maximal_classifier.predict_proba(X_train_top)[:, 1]\n",
    "#     y_prob_test_top = top_maximal_classifier.predict_proba(X_test_top)[:, 1]\n",
    "\n",
    "\n",
    "#     top_metrics = {\n",
    "#         'train_accuracy': accuracy_score(y_train, (y_prob_train_top >= optimal_threshold).astype(int)),\n",
    "#         'train_roc_auc': roc_auc_score(y_train, y_prob_train_top),\n",
    "#         'train_avg_precision': average_precision_score(y_train, y_prob_train_top),\n",
    "#         'train_recall': recall_score(y_train, (y_prob_train_top >= optimal_threshold).astype(int)),\n",
    "#         'train_precision': precision_score(y_train, (y_prob_train_top >= optimal_threshold).astype(int)),\n",
    "#         'train_f1': f1_score(y_train, (y_prob_train_top >= optimal_threshold).astype(int)),\n",
    "#         'train_mcc': matthews_corrcoef(y_train, (y_prob_train_top >= optimal_threshold).astype(int)),\n",
    "#         'test_accuracy': accuracy_score(y_test, (y_prob_test_top >= optimal_threshold).astype(int)),\n",
    "#         'test_roc_auc': roc_auc_score(y_test, y_prob_test_top),\n",
    "#         'test_avg_precision': average_precision_score(y_test, y_prob_test_top),\n",
    "#         'test_recall': recall_score(y_test, (y_prob_test_top >= optimal_threshold).astype(int)),\n",
    "#         'test_precision': precision_score(y_test, (y_prob_test_top >= optimal_threshold).astype(int)),\n",
    "#         'test_f1': f1_score(y_test, (y_prob_test_top >= optimal_threshold).astype(int)),\n",
    "#         'test_mcc': matthews_corrcoef(y_test, (y_prob_test_top >= optimal_threshold).astype(int))\n",
    "#     }\n",
    "\n",
    "#     pd.DataFrame([top_metrics]).to_csv(f'{log_dir_path}top_100_features_metrics.csv', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "#     print(\"Top 100 features model training complete\")\n",
    "\n",
    "# Feature importance for top 100 features and avoid mismatch error\n",
    "print(\"Starting iterative feature importances\")\n",
    "if maximal_classifier.feature_importances_ is not None:\n",
    "    # Retrieve the features actually used by the model\n",
    "    used_features = maximal_classifier.feature_names_in_\n",
    "\n",
    "    # Create the feature importance Series with used features only\n",
    "    feature_importance = pd.Series(maximal_classifier.feature_importances_, index=used_features)\n",
    "\n",
    "    # Get the top 100 features and map them back to original names for interpretability\n",
    "    top_features_cleaned = feature_importance.nlargest(100).index\n",
    "    top_features_original = [column_mapping.get(feature, feature) for feature in top_features_cleaned]\n",
    "    \n",
    "    # --- Start Incremental Evaluation of Top Features ---\n",
    "\n",
    "    # Prepare to store incremental results for top features\n",
    "    incremental_results = []\n",
    "\n",
    "    # Loop through 1 to 100 features, adding one feature at a time\n",
    "    for i in range(1, 101):\n",
    "        # Select the top `i` features\n",
    "        current_features = top_features_cleaned[:i]\n",
    "        X_train_top_i = X_train[current_features]\n",
    "        X_test_top_i = X_test[current_features]\n",
    "\n",
    "        # Train the model on the current subset of top features\n",
    "        incremental_classifier = AutoML()\n",
    "        incremental_classifier.fit(\n",
    "            X_train_top_i, y_train,\n",
    "            task=\"classification\", time_budget=20, metric='log_loss',\n",
    "            n_jobs=-1, eval_method='cv', n_splits=10, split_type='stratified',\n",
    "            log_training_metric=True, early_stop=True, seed=239875, estimator_list=['lgbm']\n",
    "        )\n",
    "\n",
    "        # Predict probabilities and apply optimal threshold\n",
    "        y_prob_train_i = incremental_classifier.predict_proba(X_train_top_i)[:, 1]\n",
    "        y_prob_test_i = incremental_classifier.predict_proba(X_test_top_i)[:, 1]\n",
    "        \n",
    "        y_pred_train_i = (y_prob_train_i >= optimal_threshold).astype(int)\n",
    "        y_pred_test_i = (y_prob_test_i >= optimal_threshold).astype(int)\n",
    "\n",
    "        # Record metrics for this iteration\n",
    "        result = {\n",
    "            'num_features': i,\n",
    "            'names_of_features': current_features,\n",
    "            'train_accuracy': accuracy_score(y_train, y_pred_train_i),\n",
    "            'train_roc_auc': roc_auc_score(y_train, y_prob_train_i),\n",
    "            'train_avg_precision': average_precision_score(y_train, y_prob_train_i),\n",
    "            'train_recall': recall_score(y_train, y_pred_train_i),\n",
    "            'train_precision': precision_score(y_train, y_pred_train_i),\n",
    "            'train_f1': f1_score(y_train, y_pred_train_i),\n",
    "            'train_mcc': matthews_corrcoef(y_train, y_pred_train_i),\n",
    "            'test_accuracy': accuracy_score(y_test, y_pred_test_i),\n",
    "            'test_roc_auc': roc_auc_score(y_test, y_prob_test_i),\n",
    "            'test_avg_precision': average_precision_score(y_test, y_prob_test_i),\n",
    "            'test_recall': recall_score(y_test, y_pred_test_i),\n",
    "            'test_precision': precision_score(y_test, y_pred_test_i),\n",
    "            'test_f1': f1_score(y_test, y_pred_test_i),\n",
    "            'test_mcc': matthews_corrcoef(y_test, y_pred_test_i)\n",
    "        }\n",
    "\n",
    "        incremental_results.append(result)\n",
    "\n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    incremental_results_df = pd.DataFrame(incremental_results)\n",
    "    incremental_results_df.to_csv(f'{log_dir_path}incremental_top_features_metrics.csv', index=False)\n",
    "\n",
    "    print(\"Incremental top features model training completed\")\n",
    "\n",
    "# --- End Incremental Evaluation of Top Features ---\n",
    "\n",
    "\n",
    "print(\"Maximal experiment completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d004f0-a8e1-4f36-bc7e-5401fabffb54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
